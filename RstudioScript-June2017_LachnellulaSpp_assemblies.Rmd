# Installing the required packages for R:
# This is to be done in the R command line and not in R studio
#source("https://www.Bioconductor.org/biocLite.R")
#biocLite("BiocUpgrade")


Getting started in R: Set the working directory > setwd("~/") Check version installed
```{r global_options, include=FALSE}
library(knitr)
opts_chunk$set(tidy.opts=list(width.cutoff=60), tidy = TRUE, fig.align='center')
```


This will help us when finding our files to source functions:
```{r sourcing_my_functions}
install.packages("rprojroot")
library(rprojroot)
# We specify ours is an RStudio project
# The root object contains a function that will help us locate our package r files
# regarless of our current working directory
root <- rprojroot::is_rstudio_project
scriptsPath <- root$make_fix_file(".")("R")
scripts  <- dir(root$find_file("R", path = root$find_file()))
scriptsl <- paste(scriptsPath, scripts, sep = "//")
lapply(scriptsl, source)
```

User: 
Define the path to the shared folder where the main working directory will be.
```{r setting_the_main_directory, cache=TRUE}
sharedPath <- "/home/CFIA-ACIA/girouxeml/PIRL_working_directory/"
```

User:
Specify the name and path of the csv file you would like to use for generation of the 
metadata file if not using the csv file generated by sequencing service:
*Note: I suggest saving the file in the references folder in the shared path. Getting more specific
and making a directory just for these tables is fine too - but the table will be copied to the new
directory for this analysis later in the script. It's just important to have a raw, untouched 
reference for this data kept in a place where you will remember and keep all the other ones you use.
```{r metadata_name_and_path, cache=TRUE}
metadataFileAlternate <- "lachnellula_metadata_IonT_2017.csv"
metadataPath <- paste(sharedPath, "References/", metadataFileAlternate, sep = "")
```

User:
Define the the folder in the shared folder that will hold the analyses of the 
time-course/dataset you will be working with. In our case, we have two different 
time-course experiments, Oosporogenesis and Oospore Conversion. Below we set 
which one the script will run analyses for. We also get the user to specify what 
the name of the directory that will hold the reads will be. In the case below, 
we are calling the sequencing data directory (seqDataDir) "MiSeq_data_Sci2" 
because sequencing of oospore conversion time-course reads was done on the 
in-house MiSeq and was the second run we had done on this instrument for the 
overall project. We also added Sci2 because the sequencing libraries were made 
on the SciClone robotics instrument, and also represent the second time we 
generated libraries on that instrument:
```{r analysis_and_sequence_directory, cache=TRUE}
analysis   <- "Lachnellula_species_GenomeAn_IonTorrent_2017/"
seqDataDir <- "IonTorrent_data_2017"
```

User needs to specify the adapter sequences attached to the sequencing 
reads. This will depend on how the libraries were prepared. Specify which sequencing platform was 
used to generate the reads: 
1 - MiSeq
2 - HiSeq
3 - Ion Torrent

Also specify the library layout - paired-end or single reads (Illumina only):
1 - single
2 - paired-end
```{r sequencing_platform_used, cache=TRUE}
platform      <- 3
libraryLayout <- 1
```

User:
Specify the read-processing and quality assessment tool to be used.
1 - FastQC
2 - PrinSeq
```{r read_processing_tool, cache = TRUE}
readProc <- 2
```

User:
Specify which tool to use for assembly:
1 - Newbler (for 454 and Ion Torrent reads)
2 - SPADES (for Illumina reads, mainly)
```{r assembler, cache = TRUE}
assembler <- 2
```

User:
The following paths are to directories where the references, tools and general 
requirements are located, this depends on the directories actually having been 
put there:
```{r user_tools_and_references_dir, cache=TRUE}
toolsDirPath     <- paste(sharedPath, "tools/", sep = "")
referencesPath   <- paste(sharedPath, "References/", sep = "")
fastqPEValidatorPath <- paste(toolsDirPath, "FastqPairedEndValidator.pl", sep = "")
```

We prepared our libraries using the Mondrian and SciClone with library 
kits, instruments and kits by NuGen. NuGen kits are designed to work with 
Illumina sequencing platforms and generate libraries with the sequence 
structure:

5' AATGATACGGCGACCACCGAGATCTACACTCTTTCCCTACACGACGCTCTTCCGATCT 
   (N) 
   AGATCGGAAGAGCACACGTCTGAACTCCAGTCAC <- region to select as forward adapter
   XXXXXX 
   ATCTCGTATGCCGTCTTCTGCTTG 3'
   
3' TTACTATGCCGCTGGTGGCTCTAGATGTGAGAAAGGGATGTGCTGCGAGAAGGCTAGA 
   (N) 
   TCTAGCCTTCTCGTGTGCAGACTTGAGGTCAGTG <- region to select as reverse adapter
   XXXXXX 
   TAGAGCATACGGCAGAAGACGAAC 5'

Where each string of ‘X’ is the unique 4-, 6, or 8-base barcode from the 
L2 adaptor mix of the library construction system (where applicable) 
and (N) is the library insert.

We will need to remove any adapter sequences from our reads. We will
be doing this with SeqPrep. SeqPrep specifies that the user must first 
ensure the adapter sequences they choose are correct by doing a "grep"
on the reads first:

Before running SeqPrep make sure to check that the program's defaults 
are indeed the adapters you are looking for. Try copying the default 
forward adapter from this file and grep it against your reads doing a 
word count, also try the same with the reverse adapter with grep. You 
should see some hits. You can also try using (and validating with grep) 
-A GATCGGAAGAGCACACG -B AGATCGGAAGAGCGTCGT as parameters. To find a 
list of Illumina adapter sequences you should write to Illumina tech 
support TechSupport@illumina.com (they do not like people to share the 
list of sequences outside of their institution).

Chose about 20bp of an adapter sequence where:
1. You see the most hits with grep
2. When you run a command like:
   cat Lane2_0d_2.fastq | head -n 1000000 | grep "INSERT ADAPTER HERE" | head 
   you see the adapter sequence show up at the beginning of a few reads. 
   Also the -A and -B arguments should be as they show up in your data, 
   SeqPrep searches directly for these sequences without doing reverse 
   complementing.
3. Check the forward and reverse and make sure that you have roughly the 
   same number of hits via a command to count hits like: 
   cat Lane2_0d_2.fastq | head -n 1000000 | grep "INSERT ADAPTER HERE" | wc -l
```{r setting_seq_adapters_based_on_platform, cache=TRUE}
fwdAdapHiSeq    <- "AGATCGGAAGAGCACACGTCTGAACTCCAGTCA"  # HiSeq, Genome Quebec
revAdapHiSeq    <- "AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT"  # HiSeq, Genome Quebec

# Notice that the adapter sequences we chose when processing the MiSeq reads
# is from the same region we are choosing for our HiSeq reads, only shorter:
fwdAdapMiSeq <- "AGATCGGAAGAGCACAC"   # MiSeq
revAdapMiSeq <- "AGATCGGAAGAGCGTCGT"  # MiSeq

fwdAdapIonT  <- "CCATCTCATCCCTGCGTGTCTCCGACTCAG" # "A" adapter sequence for IonTorrent
revAdapIonT  <- "CCTCTCTATGGGCAGTCGGTGAT"        # "trP1" adapter sequence for IonTorrent

if(platform == 1){
    fwdAdap <- fwdAdapMiSeq
    revAdap <- revAdapMiSeq
    print('Your sequencing platform was set to the Illumina MiSeq')} else if 
(platform == 2){
    fwdAdap <- fwdAdapHiSeq
    revAdap <- revAdapHiSeq
    print('Your sequencing platform was set to the Illumina HiSeq')} else if
(platform == 3){
    fwdAdap <- fwdAdapIonT
    revAdap <- revAdapIonT
    print('Your sequencing platform was set to the Ion Torrent')} else {
        rm(fwdAdap, revAdap)
        print('You either didn\'t specify a valid sequence platform, or none was provided')
    }
fwdAdap
revAdap
```

The user does not alter the variables below. 
```{r settingToQsubWithinRStudio, cache=TRUE}
Sys.setenv(PATH=paste('/opt/gridengine/bin/linux-x64',Sys.getenv('PATH'),sep= ':'))
```


The following chunk will integrate the user-defined variables from the previous chunk into the script.
```{r creating_dir_for_analysis, cache=TRUE}
# Create the analysis directory:
dir.create(paste(sharedPath, analysis, sep = ""), 
           showWarnings = TRUE, 
           recursive    = FALSE)

# Set the path to the analysis directory:
sharedPathAn <- paste(sharedPath, analysis, sep="")

# Create fastq directory in sharedPath folder based on "seqDataDir":
dir.create(paste(sharedPathAn, seqDataDir, sep = ""), 
           showWarnings = TRUE, 
           recursive    = FALSE)

# Set the path the fastq directory:
pathFastq <- paste(sharedPathAn, seqDataDir, "/", sep = "")
```

Path to the biocluster-installed tools:
```{r biocluster_tools_paths, cache=TRUE}
tophat2Path      <- "/opt/bio/tophat/bin/tophat2"
bowtie2BuildPath <- "/opt/bio/bowtie2/bowtie2-build"
starPath         <- "/opt/bio/STAR/STAR"
htseqCountPath   <- "/opt/bio/HTSeq/bin/htseq-count"
prinSeqPath      <- "/opt/bio/prinseq-lite/prinseq-lite"
prinSeqGraphPath <- "/opt/bio/prinseq-lite/prinseq-graphs"
samtools1Path    <- "/opt/bio/samtools1/bin/samtools1"
seqPrepPath      <- "/opt/bio/SeqPrep/SeqPrep"
itsxPath         <- "/home/CFIA-ACIA/girouxeml/prog/miniconda/bin/ITSx"
hmmDBITSxPath    <- "/home/CFIA-ACIA/girouxeml/prog/miniconda/bin/ITSx_db/HMMs/"
```

Bowtie:
Creating Bowtie reference index from the fasta file: Not done for Lachnellula willkommii
```{r bowind eval = FALSE, echo = FALSE, include = FALSE, cache=TRUE}
bowind <- "lachwiiRef"

cmd    <- paste(bowtie2BuildPath, 
                " -f ", pyuuRefPath, " ", paste(referencesPath, bowind, sep = ""),
                sep = "")
cmd
#system(cmd)
```

Below the metadata file specified by the user is copied into the analysis folder and read into R:
```{r copy_metadata_to_analysis_dir_and_read, cache=TRUE}

cmd      <- paste("cp ", metadataPath, " ", sharedPathAn, sep = "")
system(cmd)
metadata <-  read.table(paste(sharedPathAn, metadataFileAlternate, sep = ""),
                        sep = ",", header = TRUE, comment.char = "", quote = "", as.is = TRUE)
if(libraryLayout == 2){
    metadata$BaseCallsName <- paste(metadata$LibraryName, "_", 
                                    metadata$ReadDirection, ".fastq", sep = "")
} else if
(libraryLayout != 2){
    metadata$BaseCallsName <- paste(metadata$LibraryName, ".fastq", sep = "")
}
```

This function will delete qsub temp files that are the sub.e* outputs (error outputs)
```{r}
X <- function(path, prefixSub) {
  system(paste("find ", path, prefixSub, "/", prefixSub, "*", ".sub.e", "*", " -delete ", sep = ""))
}
```

Copy and gunzip files:
```{r copyRaw_gunzip, cache=TRUE}
# Copy all files using multiple processors (this is a lot faster than the above)
# cmd <- with(metadata, paste("cp ", 
#                 FastqFilePath," ", 
#                 sharedPathAn, seqDataDir, "/", basename(FastqFilePath),"\n",
#                 " gunzip ", 
#                 sharedPathAn, seqDataDir, "/", basename(metadata$FastqFilePath),
#                 sep=""))
# OR

#If you want to rename the files that you are copying over, do the following.
#It is based on what you put under BaseCallsName in your adapted metadata csv.
cmd <- with(metadata, paste("cp ", 
                FastqFilePath," ", 
                sharedPathAn, seqDataDir, "/", metadata$BaseCallsName, ".gz","\n",
                " gunzip ", 
                sharedPathAn, seqDataDir, "/", metadata$BaseCallsName, ".gz",
                sep=""))

# Generate qsub and bash files to complete the commands above:
prefix <- "A_copy_unzip" 
suffix <- ".sub"
MakeQsubs(cmd, prefix, suffix)
```

Clean-up step:
Remove the output files while keeping the qsub and bash file:
```{r, cache=TRUE}
RemoveQsubTempFiles(sharedPathAn, prefix)
```

Add the name of the raw fastq files to the metadata table
```{r, cache=TRUE}
if(libraryLayout == 2){
    for(k in 1:nrow(metadata)){
        metadata$RawFastq <- paste(metadata$LibraryName, "_", metadata$ReadDirection, ".fastq", sep = "")}
    } else if
(libraryLayout != 2){
    for(k in 1:nrow(metadata)){
        metadata$RawFastq <- paste(metadata$LibraryName, ".fastq", sep = "")
    }
}
```
The following will create a metadata table based on the library layout - paired-end or single reads.
Read pairs will be collapsed to one row per pair.
```{r, cache=TRUE}
library("reshape2")
if(libraryLayout == 2){
    metadataRawPairs <- dcast(data = metadata, LibraryName 
                              ~ ReadDirection, value.var = "BaseCallsName", FUN = c)
    metadataRawPairs$ShortName <- paste(metadataRawPairs$LibraryName)
    metadataRaw <- metadataRawPairs} else if
(libraryLayout != 2){
    metadata$ShortName <- paste(metadata$LibraryName)
    metadataRaw <- metadata} else {
        cat(c("Error: Either an incorrect number was entered for library", "\n",
              "layout (single reads = 1 and paired-end reads = 2), or no selection was", "\n",
              "specified. The default will be to consider reads single.", sep = ""))
        metadata$ShortName <- paste(metadata$LibraryName)
        metadataRaw <- metadata
        }
# We can get more specific if we want, such as when there are many samples and/or a time-course:

# metadataRawPairs$ShortName <- paste(metadataRawPairs$Condition, 
#                                     metadataRawPairs$TimePoint, 
#                                     metadataRawPairs$RNASeq_Replicate, sep = ".")
```

Looking at our raw data:
Ensure that if reads are paired-end, that they are correctly paired and ordered between read 1 and
read 2 fastq files.
```{r, cache=TRUE}
# Run FastqPairedEndValidator for the first time on the raw read pairs:
if(libraryLayout == 2){
    prefix <- "B_Validator"
    cmd <-  with (metadataRaw, paste(fastqPEValidatorPath,
                                     " ", pathFastq, R1, " ", pathFastq, R2, sep = ""))
    suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix, suffix)} else if
(libraryLayout != 2){
        cat(c("Fastq pairend end validator will not be used because you did not specify that", "\n",
              "your reads are paired end", sep = ""))
        }
#system("qstat")
```

If reads were paired-end, and the Fastq Paired-End validator was run, the output of each pair will
be displayed on the console:
```{r, echo=FALSE, cache=TRUE}
if(libraryLayout == 2){
    for (k in 1:nrow(metadataRaw)) {
        cat(c(k, metadataRaw$R1[k], metadataRaw$R2[k]))
        system(paste("cat ", sharedPathAn, prefix, "/", prefix, k, suffix, ".o*", sep = ""))
        cat("\n")}} else if
(libraryLayout != 2){
    cat(c("The fastq pairend end validator was not used because you specified that your", "\n",
              "reads are not paired end", sep = ""))
        }
```
To remove the output files after you are done:
```{r, echo=FALSE, cache=TRUE}
RemoveQsubTempFiles(sharedPathAn, prefix)
```

Look at the raw fastq graphs prior to adapter removal, QA, and other processing
using PrinSeq graph reports of raw reads, 
Step 1: .gd file generation:
```{r, echo=FALSE, cache=TRUE}
prefix <- "C_PrinSeq_rawGraphs"
if(libraryLayout == 2){
    cmd <- MakePrinSeqGraphFiles(metadataRaw, metadataRaw$R1, prefix, "rawGraphs", metadataRaw$R2)
    suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix, suffix)} else if
(libraryLayout != 2){
    cmd <- MakePrinSeqGraphFiles(metadataRaw, metadataRaw$RawFastq, prefix, "rawGraphs")
    suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix, suffix)
}
```

Add the name of the raw graphs .gd files to the 
metadata table:
```{r echo = FALSE, cache=TRUE}
for(k in 1:nrow(metadataRaw)){
  metadataRaw$RawGraphName <- paste(metadataRaw$LibraryName, ".rawGraphs.gd", sep = "") 
}
```

You can follow the progress of the PrinSeq graph generation run with the following:
```{r, echo=FALSE, cache=TRUE}
for(k in 1:nrow(metadataRaw)){
    cat(c(k, metadataRaw$LibraryName[k]))
    cat("\n")
    system(paste("cat ", sharedPathAn, prefix, "/", prefix, k, suffix, ".e*", sep = ""))
    cat("\n")}
```

PrinSeq graph reports of raw reads. 
Step 2: html file generation:
```{r echo = FALSE, cache = TRUE}
prefix2 <- "C2_PrinSeqRawGraphs"
cmd <- MakePrinSeqHTML(metadataRaw, prefix, metadataRaw$RawGraphName)
suffix <- ".sub"  
MakeQsubs(cmd, prefix2, suffix)
```
If ever you need to upload the .gd file on the PrinSeq web server to generate the html files:
http://edwards.sdsu.edu/cgi-bin/prinseq/prinseq.cgi?report=1 
You can follow the progress of the PrinSeq graph generation run with the following:
```{r, echo=FALSE, cache=TRUE}
for(k in 1:nrow(metadataRaw)){
    cat(c(k, metadataRaw$LibraryName[k]))
    cat("\n")
    system(paste("cat ", sharedPathAn, prefix2, "/", prefix2, k, suffix, ".e*", sep = ""))
    cat("\n")}
```

To remove the output files after you are done:
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix2)
```

Merging and adapter removal before processing:
Adapter detection:
```{r echo = FALSE, cache = TRUE}
if(libraryLayout == 2){
for (k in 1:nrow(metadataRaw)) {
  cat(c(k, metadataRaw$R1[k]))
  system(paste("cat ", pathFastq, metadataRaw$R1[k], " | head -n 1000000 | grep '", 
               fwdAdap, "' | wc -l ", sep = ""))
  cat("\n")
  }
    for (k in 1:nrow(metadataRaw)) {
      cat(c(k, metadataRaw$R2[k]))
      system(paste("cat ", pathFastq, metadataRaw$R2[k], " | head -n 1000000 | grep '", 
                   revAdap, "' | wc -l ", sep = ""))
      cat("\n")
      } 
    } else if
(libraryLayout != 2){
    for (k in 1:nrow(metadataRaw)) {
        cat(c(k, metadataRaw$R1[k]))
        system(paste("cat ", pathFastq, metadataRaw$RawFastq[k], " | head -n 1000000 | grep '",
                     fwdAdap, "' | wc -l ", sep = ""))
        cat("\n")
    }
}
```


Adapter removal:
```{r}
prefix <- "D_SeqPrep_adapter_Removal"
if(libraryLayout == 2){
    cmd <- with(metadataRaw, 
            paste(seqPrepPath, 
                  " -f ", pathFastq, R1,
                  " -r ", pathFastq, R2,
                  " -1 ", pathFastq, LibraryName, ".adapRem.R1.fastq.gz",
                  " -2 ", pathFastq, LibraryName, ".adapRem.R2.fastq.gz",
                  " -A ", fwdAdap,
                  " -B ", revAdap,
                  " -s ", pathFastq, paste(LibraryName, ".adapRemMerged.fastq.gz", sep = ""),
                  sep = ""))} else if 
(libraryLayout != 2){
    cmd <- with(metadataRaw, 
            paste(seqPrepPath, 
                  " -f ", pathFastq, RawFastq,
                  " -1 ", pathFastq, LibraryName, ".adapRem.fastq.gz",
                  " -A ", fwdAdap,
                  sep = ""))
}
suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix, suffix)
```

To show the output of each pair on the console in Rstudio:
```{r}
if(libraryLayout == 2){
    for(k in 1:nrow(metadataRaw)) {
      cat(c(k, metadataRaw$R1[k], metadataRaw$R2[k]))
      cat("\n")
      system(paste("tail ", sharedPathAn, prefix, "/", prefix, k, suffix, ".e* | head -n 10" , sep=""))
      cat("\n")
    }
    } else if
(libraryLayout != 2){
    for(k in 1:nrow(metadataRaw)) {
      cat(c(k, metadataRaw$RawFastq[k]))
      cat("\n")
      system(paste("tail ", sharedPathAn, prefix, "/", prefix, k, suffix, ".e* | head -n 10" , sep=""))
      cat("\n")
    }
}
```

To remove the output files after you are done:
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix)
```


Pre-Processing of Raw Reads using PrinSeq::

PrinSeq Processing of Raw reads:
PrinSeq Options Setting:
```{r}
nmax           <- 1
trimLeft       <- 15
trimRight      <- 10
trimTailLeft   <- 5   # Only for RNA-Seq - There should be no poly-tails in DNA
trimTailRight  <- 5  # Only for RNA-Seq - There should be no poly-tails in DNA
trimQualWindow <- 7 # To make this less conservative, increase from 3 to 7
trimQualType   <- "mean"
trimQualRight  <- 10 # Consider reducing from 30 to 10 initially
trimQualLeft   <- 10  # Consider reducing from 30 to 10 initially
trimQualRule   <- "lt"
lcMethod       <- "dust"
lcThreshold    <- 7
outGood        <- "processed_merged"    # Define by user
outBad         <- "null"
minLen         <- 100        # Consider reducing from 100 to 60? initially
```

For the pre-processing with PrinSeq we have three steps, with three 
sets of qsubs each:

1. Processing input raw reads with the PrinSeq trim and fitlering options
2. Generating graph files of the processed reads
3. Generating html files using the graph files to visualize the outputs

For each set of qsubs, the .log, .gd, and .html outputs are sent to the 
first folder that also has the first stage qsub and bash files. 
The processed reads are output to the pathfastq folder.

PrinSeq Processing of merged reads:
First stage of quality pre-processing with PrinSeq:

1-1. 
Filter raw.fastq output from SeqPrep by quality: Note, with 
merging with SeqPrep during adapter removal, the reads are already 
filtered and are of high quality as only the high quality reads can 
be merged.
```{r}
prefix <- "C_PrinSeqGraphQualTrim"

# I revised the function, so look to RNASeq script for how to make this work.
cmd = with(metadata, 
           paste(prinSeqPath,
                 " -fastq ",             pathFastq,  RawFastq,
                 " -trim_qual_window ",  trimQualWindow,
                 " -trim_qual_type ",    trimQualType, 
                 " -trim_qual_right ",   trimQualRight,
                 " -trim_qual_rule ",    trimQualRule,
                 " -out_good ",          paste(pathFastq, LibraryName, ".2processedRaw", sep = ""),
                 " -out_bad  ",          outBad,
                 " -verbose ",
                 " -no_qual_header ",
                 " -log ",               sharedPathAn, prefix, "/", LibraryName, ".2processedRaw.log",
                 sep = ""))

suffix <- ".sub"  
MakeQsubs(cmd, prefix, suffix)
```

Add name of quality-filtered reads .fastq files to the metadata 
tabel:
```{r}
for(k in 1:nrow(metadata)){
  metadata$processed1Fastq <- paste(metadata$LibraryName, ".2processedRaw.fastq", sep = "") 
}
```
To remove the output files after you are done:
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix)
```

Gzip the fastq reads that were INPUT to the PrinSeq processing in step 1-1, 
we won't need them and the next step in 1-2 will be using the OUTPUT processed 
reads. 
```{r}
prefix <- "C_gzipRaw"
cmd <- with(metadata, paste("gzip ", pathFastq, metadata$RawFastq, sep=""))

suffix <- ".sub"  
MakeQsubs(cmd, prefix, suffix)
```

To remove the output files after you are done:
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix)
```

1-2.
Generate PrinSeq graph files (.gd) for the fastq generated previously:
```{r}
prefix <- "C_PrinSeqGraphQualTrim"
prefix2 <- "C2_PrinSeqGraph"

cmd <- MakePrinSeqGraphFiles(metadata, metadata$processed1Fastq,
                             prefix, "2processedRaw")

suffix <- ".sub"  
MakeQsubs(cmd, prefix2, suffix)
```

You can follow the progress of the PrinSeq graph generation run with the following:
```{r, echo=FALSE, cache=TRUE}
for(k in 1:nrow(metadata)){
    cat(c(k, metadata$LibraryName[k]))
    cat("\n")
    system(paste("cat ", sharedPathAn, prefix2, "/", prefix2, k, suffix, ".e*", sep = ""))
    cat("\n")}
```

To remove the output files after you are done:
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix2)
```

Add name of quality-filtered reads .gd files to the metadata tabel:
```{r}
for(k in 1:nrow(metadata)){
  metadata$processed1GraphName <- paste(metadata$LibraryName, ".2processedRaw.gd", sep = "") 
}
```

1-3.
PrinSeq graph reports of first-stage html file generation:
**Instead of putting in the filename manually, refer to metadata for it.
```{r}
prefix3 <- "C3_PrinSeqHtml"
cmd <- MakePrinSeqHTML(metadata, prefix, metadata$processed1GraphName)

suffix <- ".sub"  
MakeQsubs(cmd, prefix3, suffix)
```

To remove the output files after you are done:
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix3)
```

Second stage of quality pre-processing with PrinSeq:
Trim left and right, and Poly-A/T tail removal, round 1
(Only for RNA-seq, not genome sequencing)
2-1.
```{r}
prefix <- "D_PrinSeqTrimLRPolyAT"

cmd <- with(metadata, 
            paste("zcat ", pathFastq, processed1Fastq, ".gz", " | ",
                  prinSeqPath,
                  " -fastq stdin ",
                  " -trim_tail_left ",  trimTailLeft,
                  " -trim_tail_right ", trimTailRight,
                  " -out_good ",        paste(pathFastq, LibraryName, ".3processed", sep = ""),
                  " -out_bad  ",        outBad,
                  " -verbose ",
                  " -no_qual_header ",
                  " -log ",             paste(sharedPathAn, prefix, "/", LibraryName, ".3processed.log", 
                                              sep = ""),
                  sep = ""))

suffix <- ".sub"  
MakeQsubs(cmd, prefix, suffix)
```

(Only for RNA-seq, not genome sequencing)
To remove the output files after you are done:
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix)
```

(Only for RNA-seq, not genome sequencing)
Add name of Poly-A/T, left and right trimmed reads .fastq files to the 
metadata tabel:
```{r}
for(k in 1:nrow(metadata)){
  metadata$processed2Fastq <- paste(metadata$LibraryName, ".3processed.fastq", sep = "") 
}
```


2-2.
(Only for RNA-seq, not genome sequencing)
Generate PrinSeq graph files (.gd) for the fastq generated previously:
This works, but the temp files are large - so beware of disc usage.
```{r}
prefix2 <- "D2_PrinSeqGraphTrimLRPolyAT"

cmd <- MakePrinSeqGraphFiles(metadata, metadata$processed2Fastq,
                             prefix, "3processed")

# prefix5 <- "D5_PrinSeqGraphTrimLRPolyAT"
# cmd <- MakePrinSeqGraphFiles2(metadata, metadata$processed2Fastq,
#                              prefix, "3processed")


suffix <- ".sub"  
MakeQsubs(cmd, prefix2, suffix)
```

(Only for RNA-seq, not genome sequencing)
To remove the output files after you are done:
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix2)
```


Gzip the fastq reads that were output to the PrinSeq processing in step 2-1, 
input reads stayed compressed - no need to compress those. Had to stop this
testing of submitting by qsub.
```{r}
prefix3 <- "C_gzipProcessed"

cmd <- with(metadata, paste("gzip ", pathFastq, 
                           #  metadata$processed2Fastq,
                            metadata$processed1Fastq, sep = ""))
# suffix <- ".sub"  
MakeQsubs(cmd, prefix3, suffix)
```

To remove the output files after you are done:
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix3)
```

(Only for RNA-seq, not genome sequencing)
Add name of trimmedLR/PolyAT reads .gd files to the metadata tabel: (Done)
```{r}
for(k in 1:nrow(metadata)){
  metadata$processed2GraphName <- paste(metadata$LibraryName, ".3processed.gd", sep = "") 
}
```


2-3.
(Only for RNA-seq, not genome sequencing)
PrinSeq graph reports of second-stage html file generation:
```{r}
prefix4 <- "D4_PrinSeq_html"

cmd <- MakePrinSeqHTML(metadata, prefix, metadata$processed2GraphName)

suffix <- ".sub"  
MakeQsubs(cmd, prefix4, suffix)
```

(Only for RNA-seq, not genome sequencing)
To remove the output files after you are done:
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix4)
```

(Only for RNA-seq, not genome sequencing)
Third stage of quality pre-processing with PrinSeq:
Poly-A/T tail removal, round 2:
Repeat poly tails trimming, because after trimming ends that had AAAAATTTTT 
that has been trimmed for the poly-T will still have the poly-A string.
3-1.
```{r}
prefix <- "E_PrinSeq2ndPolyAT"

cmd <- with(metadata, 
            paste("zcat ", pathFastq, processed2Fastq, ".gz", " | ",
                  prinSeqPath,
                  " -fastq stdin ",
                  " -trim_tail_left ",  trimTailLeft,
                  " -trim_tail_right ", trimTailRight,
#                 " -out_good ",        paste(pathFastq, LibraryName, ".4processed", sep = ""),
                  " -out_good stdout ",
                  " -out_bad  ",        outBad,
                  " -verbose ",
                  " -no_qual_header ",
                  " -log ",             paste(sharedPathAn, prefix, "/", 
                                              LibraryName, ".4processed.log", 
                                              sep = ""),
                  " |  gzip > ", paste(pathFastq, LibraryName,
                                       ".4processed.fastq.gz", sep = ""), 
                  sep = ""))


suffix <- ".sub"  
MakeQsubs(cmd, prefix, suffix)
```

(Only for RNA-seq, not genome sequencing)
To remove the output files after you are done:
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix)
```

(Only for RNA-seq, not genome sequencing)
Add name of 2nd polyAT trimmed reads .fastq files to the 
metadataAdapRM tabel:
```{r}
for(k in 1:nrow(metadata)){
  metadata$processed3Fastq <- paste(metadata$LibraryName, ".4processed.fastq", sep = "") 
}
```

3-2.
(Only for RNA-seq, not genome sequencing)
Generate PrinSeq graph files (.gd) for the fastq generated the previously:
```{r}
prefix2 <- "E2_PrinSeq2ndTrimPolyATgraphs"

cmd <- MakePrinSeqGraphFiles2(metadata, metadata$processed3Fastq, prefix, "4processed")

suffix <- ".sub"  
MakeQsubs(cmd, prefix2, suffix)
```

(Only for RNA-seq, not genome sequencing)
To remove the output files after you are done:
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix2)
```

(Only for RNA-seq, not genome sequencing)
Add name of second trimmed PolyAT reads .gd files to the metadata tabel:
```{r}

for(k in 1:nrow(metadata)){
  metadata$processed3GraphName <- paste(metadata$LibraryName, ".4processed.gd", sep = "") 
}
```


3-3.
(Only for RNA-seq, not genome sequencing)
PrinSeq graph reports of third-stage html file generation:
```{r}
prefix3 <- "E3_PrinSeq_html"

cmd <- MakePrinSeqHTML(metadata, prefix, metadata$processed3GraphName)

suffix <- ".sub"  
MakeQsubs(cmd, prefix3, suffix)
```

(Only for RNA-seq, not genome sequencing)
To remove the output files after you are done:
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix3)
```


Fourth and LAST stage of quality pre-processing with PrinSeq:
Filtering of reads by complexity (DUST) and minimum length
4-1.
```{r}
prefix <- "D_PrinSeqDustMinLen"

cmd <- with(metadata, 
            paste("zcat ", pathFastq, processed1Fastq, ".gz", " | ",
                  prinSeqPath,
                  " -fastq stdin ",
                  " -min_len ",        minLen,
                  " -lc_method ",      lcMethod,
                  " -lc_threshold ",   lcThreshold,
                  " -out_good stdout ",
                  " -out_bad  ",       outBad,
                  " -verbose ",
                  " -no_qual_header ",
                  " -log ",            paste(sharedPathAn, prefix, "/", LibraryName, ".3processed.log", 
                                             sep = ""),
                  " |  gzip > ", paste(pathFastq, LibraryName, ".3processed.fastq.gz", sep = ""), 
                  sep = ""))


suffix <- ".sub"  
MakeQsubs(cmd, prefix, suffix)
```


```{r}
for(k in 1:nrow(metadata)){
  metadata$processed2Fastq <- paste(metadata$LibraryName, ".3processed.fastq", sep = "") 
}
for(k in 1:nrow(metadata)){
  metadata$finalProcessedPath <- paste(pathFastq, "/", metadata$LibraryName, ".3processed.fastq", sep = "") 
}
```

To remove the output files after you are done:
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix)
```

4-2
Generate PrinSeq graph files (.gd) for the fastq generated the previously:
```{r}
prefix2 <- "D2_PrinSeqDustMinLength"

cmd <- MakePrinSeqGraphFiles2(metadata, metadata$processed2Fastq, prefix, "3processed")

suffix <- ".sub"  
MakeQsubs(cmd, prefix2, suffix)
```

Add name of Dust and MinLen filtered reads .gd files to the metadata tabel:
```{r}
for(k in 1:nrow(metadata)){
  metadata$processed2GraphName <- paste(metadata$LibraryName, ".3processed.gd", sep = "") 
}
```

To remove the output files after you are done:
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix2)
```

```{r}
system("/opt/gridengine/bin/linux-x64/qstat") # Remove qsub temp when qstat returns nothing.
# RemoveQsubTempFiles(sharedPathAn, prefix)
```

Get ITS sequences:
Use FungalITSextractor perl script to get the ITS sequences.
1st: Gunzip the fastq file:
```{r}
prefix <- "F_ITS_fastqGunzip"
cmd <- with(metadata, 
            paste("gunzip ", pathFastq, processed2Fastq, ".gz", sep = ""))
cmd[1]
suffix <- ".sub"  
MakeQsubs(cmd, prefix, suffix)
```
To remove the output files after you are done:
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix)
```

2nd: Convert the Fastq to fasta file format:
```{r}
prefix <- "F2_ITS_fastq2fasta"
cmd    <- with(metadata,
               paste(" seqtk fq2fa ", paste(pathFastq, processed2Fastq, sep = ""),
                     " > ", paste(pathFastq, LibraryName, ".3processed.fasta", sep = ""),
                     sep = ""))
cmd[1]
suffix <- ".sub"  
MakeQsubs(cmd, prefix, suffix)

metadata$processed2Fasta <- paste(metadata$LibraryName, ".3processed.fasta", sep = "")
```

3rd: Use ITSx to extract ITS sequences:
Note: The hmmer version on the biocluster, with the /opt/bio/ITSx/bin/HMMs is outdated and causes ITSx to crash.
I downloaded hmmer-3.1b2 locally in /home/CFIA-ACIA/girouxeml/prog/hmmer-3.1b2 and copied over the /bin/HMMs directory
to the ~/prog/hmmer-3.1b2/bin directory and re-ran the ITSx program with the --reset T option and the -p ~/prog/hmmer-3.1b2/bin/HMM
option to point to the local HMM directory, where I also have write privileges. This allows the ITSx program to 
rebuild the problematic hmm files and successfully run. The command line performed was:
$ perl /opt/bio/ITSx/bin/ITSx -i ../IonTorrent_data_2018/Phra1_7964.3processed.fasta -t F -p ~/prog/hmmer-3.1b2/bin/HMMs/ --save_regions all --table T --reset T --cpu 16 -o Phra1_7964   
After creating the bash files inthe chunk below, I navigate to the directory they are in and run each with:  
$ qsub -pe smp 20 -cwd -S /bin/bash "name of bash file"   
Otherwise the multi-threaded, parallel cpu options are not used with the .sh qsub script.  

*** Over here - running 11June2018  
Also note that it takes a long time, and perhaps I should have added the option for threaded on top of --cpu.
```{r}
prefix <- "F3_ITS_ITSx"
cmd    <- with(metadata,
               paste("perl ", itsxPath,
                     " -i ", paste(pathFastq, processed2Fasta, sep = ""),
                     " -p ", hmmDBITSxPath, 
                     " -t F --save_regions all --table T --reset T --cpu 20 --multi_thread T ",
                     " -o ", LibraryName,
                     sep = ""))
cmd[1]
suffix <- ".sub"
MakeQsubs(cmd, prefix, suffix, node)
```

Assembling de novo:
ABySS
IDBA-UD (can't get it to work, tried with -l option for long reads)
SOAPdenovo(SOAP) (we won't use this - it's for short reads)
SPAdes
Newbler
SparseAssembler(Sparse)
Velvet (we won't use this - it's for short reads)
```{r}
pathkmerGenie <- "/home/CFIA-ACIA/girouxeml/prog/kmergenie-1.7044/kmergenie"
pathABYSS <- "/opt/bio/abyss/bin/ABYSS"
pathIDBAud <- "/opt/bio/idba/bin/idba_ud"
pathSOAPdenovo <- "opt/bio/SOAPdenovo2/SOAPdenovo-63mer"
pathVelvet <- "/opt/bio/velvet/"
```

Gather fasta data required for all assemblies:
```{r}
library(data.table)
metadata_dt <- as.data.table(metadata)
setkey(metadata_dt, ScientificName, LibraryName, processed2Fastq, finalProcessedPath)

head(metadata_dt)
key(metadata_dt)
metadataAssembly <- metadata_dt[, c("ScientificName", "LibraryName", "processed2Fastq", "finalProcessedPath"), with=FALSE]
# metadataAssemblyLawii <- data.table("ScientificName"=c("Lachnellula_willkommii"),
#                                     "LibraryName"=c("Lawi_IonT_Debbie_1"),
#                                     "processed2Fastq"=c("wholeGen_Lawii.5processed.fastq"),
#                                     "finalProcessedPath"= c(paste(sharedPath, "Lachnellula_willkommii_GenomeAn/IonTorrent_data_Debbie1/wholeGen_Lawii.5processed.fastq",
#                                                             sep = "")))
# metadataAssembly <- rbind(metadataAssembly, metadataAssemblyLawii)

# This was moved up from dbCAN much later in the script - need to be careful this is the right order
# according to the table at this point.
sppAbbr <- c("Fus3", "Phra1", "Phra2" )
metadataAssembly$SppAbbr <- sppAbbr
```

```{r}
prefix <- "kmerGenie"

cmd <- paste(pathABYSS, " --help", sep = "")
cmd <- paste(pathkmerGenie, " --help", sep = "")
system(cmd)

cmd <- with(metadataAssembly,paste(pathkmerGenie, " ", finalProcessedPath, ".gz", " -o ", LibraryName, sep = ""))

suffix <- ".sub"  
MakeQsubs(cmd, prefix, suffix)
```

To remove the output files after you are done:
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix)
```

Add the best k-mer values identified by kmergenie for each genome and the predicted assembly size:
```{r}
pathKmerGenieDat <- paste(sharedPath, analysis, "kmerGenie/", sep = "")

for(k in 1:nrow(metadataAssembly)){
  metadataAssembly$kmerGenieDat <- paste(metadataAssembly$LibraryName, ".dat", sep = "") 
  metadataAssembly$kmerGenieDatPath <- paste(pathKmerGenieDat, metadataAssembly$kmerGenieDat, sep = "")
}

for(i in 1:nrow(metadataAssembly)){
    kmerdatTmp <- fread(metadataAssembly$kmerGenieDatPath[i], sep = "auto", header = TRUE)
    setkey(kmerdatTmp, genomic.kmers)
    key(kmerdatTmp)
    maxGenomicKmers <- max(kmerdatTmp$genomic.kmers)
    metadataAssembly$BestKmerGenie[i] <- kmerdatTmp[.(maxGenomicKmers), .(k)]
}
```

Assemble with ABySS and the kmer best from kmergenie:
```{r}
cmd <- paste(pathABYSS, " --help", sep = "")
system(cmd)

prefix <- "Assembly_ABySS"

for(i in 1:nrow(metadataAssembly)){
cmd <- with(metadataAssembly, paste(pathABYSS, " -k ", metadataAssembly$BestKmerGenie, 
                                    " ", paste(metadataAssembly$finalProcessedPath, ".gz", sep = ""), 
                                    " -o ", paste("kmer_", metadataAssembly$BestKmerGenie, "_", LibraryName, ".fastq", sep = ""),
                                    " --coverage-hist ", paste(sharedPath, analysis, prefix, "/",
                                                               "kmer_", metadataAssembly$BestKmerGenie, "_",
                                                               LibraryName, ".hist", sep = ""),
                                    " -v -q 10 ", sep = ""))
}

suffix <- ".sub"  
MakeQsubs(cmd, prefix, suffix)
```

Add the names of the genome fastq files assembled with ABySS, and their paths to the metadata table:
```{r}
for(k in 1:nrow(metadataAssembly)){
  metadataAssembly$ABySSfastq <- paste("kmer_", metadataAssembly$BestKmerGenie, "_", metadataAssembly$LibraryName, ".fastq", sep = "")
  metadataAssembly$ABySSfastqPath <- paste(sharedPath, analysis, "Assembly_ABySS/", metadataAssembly$ABySSfastq, sep = "")
}
```

Creating a blast database using previous Lachnellula willkommii genome assembly done with Newbler, 
and then blasting the ABySS assembly fastqs for all the genomes against it:
```{r}
# To make the database:

 # makeblastdb -in /home/CFIA-ACIA/girouxeml/PIRL_working_directory/Lachnellula_willkommii_GenomeAn/IonTorrent_data_Debbie1/Assembly1_NewblerAllGCrange/454AllContigs.fna -input_type fasta -dbtype nucl -hash_index -parse_seqids

# To Blast against it:

# blastn -query /home/CFIA-ACIA/girouxeml/PIRL_working_directory/Lachnellula_species_GenomeAn_IonTorrent_2017/Assembly_ABySS/kmer_81_Lawi_IonT_Debbie_1.fastq -db /home/CFIA-ACIA/girouxeml/PIRL_working_directory/Lachnellula_willkommii_GenomeAn/IonTorrent_data_Debbie1/Assembly1_NewblerAllGCrange/454AllContigs.fna -out ./Lawii_454AllContigs.blastn -outfmt '6 qseqid sseqid stitle pident length mismatch gapopen qstart qend sstart send evalue bitscore' -num_threads $(nproc) -max_target_seqs 1

prefix <- "LawiiMitodbBlast"

for(k in 1:nrow(metadataAssembly)){
    cmd <- paste("blastn ", 
                 "-query ", metadataAssembly$NewblerFnaPath,
                 " -db ", paste(sharedPath, "data/Lachnellula_willkommii/Final_Sequences/Mitochondrial_from_contig00001.fasta", sep = ""),
                 " -out ", paste("./", metadataAssembly$LibraryName, "_454AllContigs.blastn", sep = ""),
                 " -outfmt ", "'6 qseqid sseqid pident length mismatch gapopen qstart qend sstart send evalue bitscore' -num_threads $(nproc) -max_target_seqs 1",
                 sep = "")
}
suffix <- ".sub"  
MakeQsubs(cmd, prefix, suffix)
```

Get the ABySS assembly contiguity metrics
```{r}
pathABYSSfac <- "/opt/bio/abyss/bin/abyss-fac"

prefix <- "Assembly_ABySS-fac"

for(i in 1:nrow(metadataAssembly)){
    cmd <- with(metadataAssembly, paste(pathABYSSfac, " ", metadataAssembly$ABySSfastqPath,
                                        " -v ", sep = ""))
}

suffix <- ".sub"  
MakeQsubs(cmd, prefix, suffix)
```

To remove the error output files after you are done: (we need the sub.o* to gather the stats)
```{r}
X(sharedPathAn, prefix)
```

ABySS Contig stats output format:

Column	Description
n	    Total number of sequences
n:500	Number of sequences at least 500 bp
L50	    Number of sequences at least the N50 size
LG50	Number of sequences at least the NG50 size
NG50	Half the genome is in sequences of the NG50 size or larger
min	    The size of the smallest sequence
N80	    At least 80% of the assembly is in sequences of the N80 size or larger
N50	    At least half the assembly is in sequences of the N50 size or larger
N20	    At least 20% of the assembly is in sequences of the N20 size or larger
E-size	The sum of the square of the sequence sizes divided by the assembly size
max	    The size of the largest sequence
sum	    The sum of the sequence sizes
name	The file name of the assembly
```{r}
library(reshape2)
pathABySS_fac_results <- paste(sharedPath, analysis, prefix, "/", sep = "")
list.files(pathABySS_fac_results, Sys.glob("*.sub.o*"))
listABySS_fac_res <- Sys.glob(file.path(pathABySS_fac_results, "*.sub.o*"))


i <- 1
for(i in 1:length(listABySS_fac_res)){
    test[[i]] <- fread(listABySS_fac_res[i], sep = "auto", header = TRUE)
    test[[i]]$ABySSfastq <- basename(test[[i]]$name)
    print(nrow(test[[i]]))
}

summary(test)
View(test[[1]])

library(data.table)
testList <- list(test[[1]], test[[2]], test[[3]], test[[4]], test[[5]], test[[6]], test[[7]])
testAll <- Reduce(function(x, y) merge(x, y, all=TRUE), testList)

write.table(testAll, file = file.path(paste(sharedPathAn, analysis, "ABySS_Assembly_Contiguity_Stats_all_genomes.csv", sep = "")),
            append = FALSE,
            quote  = FALSE,
            row.names = FALSE,
            sep = ",",
            col.names = TRUE)
```

Mapping against reference Assemblies:
```{r}
fus3RefAssem   <- "refFastaAssemblyEnsembleFungi_Fusarium_langsethiae_JXCE01.fasta"
fus3RefAssPath <- paste(referencesPath, fus3RefAssem, sep = "")
phraRefAssem   <- "refAssemblyEnsemble_Phytophtora_ramorum_AAQX01.fasta"
phraRefAssPath <- paste(referencesPath, phraRefAssem, sep = "")
```

Assembling with Newbler
Must first gunzip the fastq as Newbler can't use compressed files!
```{r}
prefix <- "GunZipForNewbler"

for(i in 1:nrow(metadataAssembly)){
    cmd <- with(metadataAssembly, 
            paste(" gunzip ", paste(metadataAssembly$finalProcessedPath, ".gz", sep = ""),
                  sep = ""))
}

suffix <- ".sub" 
MakeQsubs(cmd, prefix, suffix)
```

To remove the output files after you are done:
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix)
```

*** Over here ** started assembling with Newbler 11June2018  
```{r}
newblerPath <- "/opt/bio/454/bin/newbler"
runAssPath  <- "/opt/bio/454/bin/runAssembly"

prefix <- "Assembly_Newbler"
node <- "20"
for(i in 1:nrow(metadataAssembly)){
    cmd <- with(metadataAssembly, 
                paste(runAssPath, 
                      " -o ", paste(sharedPath, analysis, prefix, "/", metadataAssembly$LibraryName, sep = ""),
                      " -cpu ", node, " ",    paste(metadataAssembly$finalProcessedPath, sep = ""), 
                      sep = ""))
}
cmd[1] # cmd to re-run Lari only due to previous run crash   
suffix <- ".sub" 

MakeQsubs(cmd, prefix, suffix)
# MakeQsubs(cmd[1], prefix2, suffix, node) # For re-running Lari due to previous run crash.
```
* done
To remove the output files after you are done:
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix2)
```

Add the assembled contigs paths from Newbler to the metadata table:
```{r}
for(k in 1:nrow(metadataAssembly)){
  metadataAssembly$NewblerFnaPath <- paste(sharedPath, analysis, "Assembly_Newbler/", metadataAssembly$LibraryName, "/454AllContigs.fna", sep = "")
}
```

* done
Must first gzip the fastq after Newbler assembly to save space!
```{r}
prefix <- "GZipAfterNewbler"

for(i in 1:nrow(metadataAssembly)){
    cmd <- with(metadataAssembly, 
            paste(" gzip ", paste(metadataAssembly$finalProcessedPath, sep = ""),
                  sep = ""))
}

suffix <- ".sub" 
MakeQsubs(cmd, prefix, suffix)
```

To remove the output files after you are done:
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix)
```

Assembling genomes with SPades:
```{r}
pathSpades <- "/home/CFIA-ACIA/girouxeml/prog/SPAdes-3.10.1-Linux/bin/spades.py"
prefix <- "Assembly_SPAdesMultipleKmers"

for(i in 1:nrow(metadataAssembly)){
    cmd <- with(metadataAssembly, 
                paste(pathSpades, " ", 
                      " --iontorrent ",
                      " -k ", "21,33,45,57,69,81,93,105,117,127",
                      " -o ", paste(sharedPath, analysis, prefix, "/", metadataAssembly$LibraryName, sep = ""),
                      " -s ", metadataAssembly$finalProcessedPath,
                      sep = "")
    )
}
suffix <- ".sub" 
MakeQsubs(cmd, prefix, suffix)
```

To delete the qsub outputs errors only, in case the sub.o* have info we need to gather.
```{r}
X(sharedPathAn, prefix)
```

Add the assembled contigs paths from SPAdes to the metadata table:
```{r}
for(k in 1:nrow(metadataAssembly)){
  metadataAssembly$SPAdesFastaPath <- paste(sharedPath, analysis, "Assembly_SPAdesMultipleKmers/", 
                                          metadataAssembly$LibraryName, "/scaffolds.fasta", sep = "")
}
```

* done
Quast to evaluate assemblies and see how assemblies compared if using ABySS, SPAdes, or Newbler.
Note: in the end the best assemblies came from using Newbler, and the assembly metrics provided by Newbler were recorded.
```{r}
pathQuast <- "/opt/bio/quast/quast.py"

prefix <- "Assembly_Assessment_Quast"

for(i in 1:nrow(metadataAssembly)){
    cmd <- with(metadataAssembly, 
                paste(pathQuast, " ", 
                      " -o ", paste(sharedPath, analysis, prefix, "/", metadataAssembly$LibraryName, "/", sep = ""),
                      #" -l ", metadataAssembly$LibraryName,
                      " -e ", # " -f",
                      " ", metadataAssembly$ABySSfastqPath, 
                      " ", metadataAssembly$SPAdesFastaPath, 
                      " ", metadataAssembly$NewblerFnaPath,
                      sep = ""))
}

suffix <- ".sub" 
MakeQsubs(cmd, prefix, suffix)
```

To remove the output files after you are done:
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix)
```

Usage: python /opt/bio/quast/quast.py [options] <files_with_contigs>

Options:
-o  --output-dir  <dirname>   Directory to store all result files [default: quast_results/results_<datetime>]
-R                <filename>  Reference genome file
-G  --genes       <filename>  File with gene coordiantes in the reference
-O  --operons     <filename>  File with operon coordiantes in the reference
    --min-contig  <int>       Lower threshold for contig length [default: 500]

Advanced options:
-T  --threads      <int>              Maximum number of threads [default: number of CPUs]
-l  --labels "label, label, ..."      Names of assemblies to use in reports, comma-separated. If contain spaces, use quotes
-L                                    Take assembly names from their parent directory names
-f  --gene-finding                    Predict genes (with GeneMarkS from prokaryotes (default), GlimmerHMM
                                      for eukaryotes (--eukaryote), or MetaGeneMark for metagenomes (--meta)
-S  --gene-thresholds                 Comma-separated list of threshold lengths of genes to search with Gene Finding module
                                      [default is 0,300,1500,3000]
-e  --eukaryote                       Genome is eukaryotic
-m  --meta                            Metagenomic assembly. Use MetaGeneMark for gene prediction.
    --est-ref-size <int>              Estimated reference size (for computing NGx metrics without a reference)
    --gage                            Use GAGE (results are in gage_report.txt)
-t  --contig-thresholds               Comma-separated list of contig length thresholds [default: 0,1000]
-s  --scaffolds                       Assemblies are scaffolds, split them and add contigs to the comparison
-u  --use-all-alignments              Compute genome fraction, # genes, # operons in the v.1.0-1.3 style.
                                      By default, QUAST filters Nucmer's alignments to keep only best ones
-a  --ambiguity-usage <none|one|all>  Use none, one, or all alignments of a contig with multiple equally
                                      good alignments [default is one]
-n  --strict-NA                       Break contigs in any misassembly event when compute NAx and NGAx
                                      By default, QUAST breaks contigs only by extensive misassemblies (not local ones)

    --test                            Run QUAST on the data from the test_data folder, output to test_output
-h  --help                            Print this message


* Not Done for Lari yet
```{r}
library(Biostrings)
i <- 1
for(i in 2:nrow(metadataAssembly)){
    tempFasta <- readDNAStringSet(metadataAssembly$NewblerFnaPath[i], format = "fasta")
    tempContig1 <- tempFasta[1]
    names(tempContig1) = sub(" .*", "", names(tempContig1))
    names(tempContig1) = paste(names(tempContig1), "_", metadataAssembly$LibraryName[i], sep = "")
    writeXStringSet(tempContig1, 
                    file = paste(sharedPathAn, "Newbler_Contig1_all_Lachnellula.fasta", sep = ""), 
                    append = TRUE, 
                    format = "fasta") 
}

pathContig1 <- paste(sharedPathAn, "Newbler_Contig1_all_Lachnellula.fasta", sep = "")
for(i in 1:length(ID_fasta_files)){
  cmd <- paste("/opt/bio/mafft/bin/mafft --reorder --quiet '",  pathContig1, "' > ", 
             pathContig1, "_mafft_aligned.fasta", sep = "")
  system(cmd)
}
```

* Done
This is to see about contaminating sequence profile using Kraken, with Krona for visualization.
```{r}
pathKraken <- "/home/CFIA-ACIA/girouxeml/prog/kraken/kraken"
krakenDB <- "/home/CFIA-ACIA/girouxeml/Kraken_first_DataBase"

dir.create(paste(sharedPathAn, "krakenContaminationTesting", sep = ""), showWarnings=TRUE, recursive=FALSE)
pathKrakenTests <- paste(sharedPathAn, "krakenContaminationTesting/", sep = "")

prefix <- "kraken_testingQsubs"
cmd <- with(metadataAssembly,
            paste(pathKraken,
                  " --preload ",
                  " --db ", krakenDB,
                  " --fastq-input",
                  " --threads 12 ",
                  " --output ", paste(pathKrakenTests, "krakenTesting_", 
                                      metadataAssembly$LibraryName, ".output", sep = ""),
                  " ", paste(metadataAssembly$finalProcessedPath, sep = ""),
                  sep = ""))

# Note, if there are a lot of qsubs to run, some may terminate due to lack of
# available memory to run on the cluster. You can see which ones didn't run 
# by cd into the directory with the qsubs, and on the command line do:
# $  find . -type f -exec grep -H 'Cannot allocate memory' {} \;
# You can then run these separately after the others are complete.
# So far, one of the 6, L. ari will need to be resubmitted because of this.

suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix, suffix)
```
* Done
Clean-up step: Remove the output files while keeping the qsub and bash file:
```{r}
system("/opt/gridengine/bin/linux-x64/qstat") # Remove qsub temp when qstat returns nothing.
RemoveQsubTempFiles(sharedPathAn, prefix)
```
* Done
To add the kraken output files to the metadata table:
```{r}
for(k in 1:nrow(metadataAssembly)){
  metadataAssembly$KrakenOutput <- paste("krakenTesting_", metadataAssembly$LibraryName, ".output", sep = "") 
}
```
* Done
For users who want the full taxonomic name associated with each input sequence, 
use kraken-translate to produce two different output formats for classified sequences. 
The script operates on the output of kraken, like so: 
kraken-translate --db $DBNAME sequences.kraken > sequences.labels
```{r}

prefix <- "krakenTranslateQsubs"
pathKrakenTranslate <- "/home/CFIA-ACIA/girouxeml/prog/kraken/kraken-translate"

cmd <- with(metadataAssembly,
            paste(pathKrakenTranslate,
                  " --db ", krakenDB,
                  " ", paste(pathKrakenTests, metadataAssembly$KrakenOutput, sep = ""),
                  " > ", paste(pathKrakenTests, "krakenTesting_", metadataAssembly$LibraryName,
                               ".labels", sep = ""),
                  sep = ""))

suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix, suffix)
```

* Done
Clean-up step: Remove the output files while keeping the qsub and bash file:
```{r}
system("/opt/gridengine/bin/linux-x64/qstat") # Remove qsub temp when qstat returns nothing.
RemoveQsubTempFiles(sharedPathAn, prefix)
```
* Done
To add the kraken output files to the metadata table:
```{r}
for(k in 1:nrow(metadataAssembly)){
  metadataAssembly$KrakenOutputLabels <- paste("krakenTesting_", metadataAssembly$LibraryName, ".labels", sep = "") 
}
```

* Done
After blasting our sequences against our Kraken database, we tabulate the results using the following:
```{r}
prefix <- "krakenReportQsubs"
pathKrakenResults <- "/home/CFIA-ACIA/girouxeml/prog/kraken/kraken-report"

cmd <- with(metadataAssembly,
            paste(pathKrakenResults,
                  " --db ", krakenDB,
                  " ", paste(pathKrakenTests, metadataAssembly$KrakenOutput, sep = ""),
                  " > ", paste(pathKrakenTests, "krakenTesting_", metadataAssembly$LibraryName,
                               ".report", sep = ""),
                  sep = ""))

suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix, suffix)
```
* Done
Clean-up step: Remove the output files while keeping the qsub and bash file:
```{r}
system("/opt/gridengine/bin/linux-x64/qstat") # Remove qsub temp when qstat returns nothing.
RemoveQsubTempFiles(sharedPathAn, prefix)
```

* Done
To visualize the kraken data, we can use krona:
```{r}
prefix <- "KrakenToKronaInFormatQsub-outputIn"
pathKronaImportTax <- "/home/CFIA-ACIA/girouxeml/prog/bin/ktImportTaxonomy"

cmd <- with(metadataAssembly,
            paste("cut -f2,3 ", 
                  paste(pathKrakenTests, metadataAssembly$KrakenOutput, sep = ""),
                  " > ", 
                  paste(pathKrakenTests, "krona_outputIn_", metadataAssembly$LibraryName, ".in", sep = ""),
                  sep = ""))
suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix, suffix)
```
* Done
Clean-up step: Remove the output files while keeping the qsub and bash file:
```{r}
system("/opt/gridengine/bin/linux-x64/qstat") # Remove qsub temp when qstat returns nothing.
RemoveQsubTempFiles(sharedPathAn, prefix)
```
* Done
To add the kraken output files to the metadata table:
```{r}
for(k in 1:nrow(metadataAssembly)){
  metadataAssembly$KronaIn <- paste("krona_outputIn_", metadataAssembly$LibraryName, ".in", sep = "") 
}
```

* Done
Passing in to krona:
```{r}
prefix <- "kronaQsubs_OutputIn"
pathKronaImportTax <- "/home/CFIA-ACIA/girouxeml/prog/bin/ktImportTaxonomy"

cmd <- with(metadataAssembly,
            paste(pathKronaImportTax, " ", 
                  paste(pathKrakenTests, metadataAssembly$KronaIn, sep = ""),
                  " -o ", 
                  paste(pathKrakenTests, "krona_outputIn_", metadataAssembly$LibraryName, ".out.html", sep = ""),
                  sep = ""))
suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix, suffix)
```

* Done
Clean-up step: Remove the output files while keeping the qsub and bash file:
```{r}
system("/opt/gridengine/bin/linux-x64/qstat") # Remove qsub temp when qstat returns nothing.
RemoveQsubTempFiles(sharedPathAn, prefix)
```

Add the names of the blast output files for mitochondrial hits to the metadata table:
```{r}
list.files(paste(sharedPathAn, "LawiiMitodbBlast/", sep = ""))
for(k in 1:nrow(metadataAssembly)){
    metadataAssembly$LawiiMitoBlast <- paste(metadataAssembly$LibraryName, "_454AllContigs.blastn", sep = "")
    metadataAssembly$LawiiMitoBlastPath <- paste(sharedPathAn, "LawiiMitodbBlast/", metadataAssembly$LawiiMitoBlast, sep = "")
}
```

Read in a blast output file from the LawiiMitodbBlast qsub
```{r}
library(data.table)
i = 2
i = 1
# Until Lari assembly with newbler is done, don't select that row:
metadataAssemblySubTemp <- metadataAssembly[2:7,]

for(i in 1:nrow(metadataAssemblySubTemp)){
    blastnTmp <- fread(metadataAssemblySubTemp$LawiiMitoBlastPath[i], sep = "auto", header = FALSE)
    names(blastnTmp) <- c("qseqid", "sseqid", "pident", "length", "mismatch", 
                          "gapopen", "qend", "sstart", "send", "evalue", "bitscore")
    blastnTmp$LibraryName <- metadataAssemblySubTemp$LibraryName[i]
    blastnTmp$NewblerFnaPath <- metadataAssemblySubTemp$NewblerFnaPath[i]
    blastnTmp <- blastnTmp[, .(LibraryName, NewblerFnaPath, qseqid, pident, length, mismatch, gapopen, evalue)]
    if (i == 1){
        blastnNew <- blastnTmp
    } else {
        blastnNew <- rbind(blastnNew, blastnTmp)
    }
}

# Retrieve the contigs per genome in the blastnNew data table, edit the name to include the Library Name
# and then write separate fastq sets per library name...

library(Biostrings)
i <- 1
for(i in 1:nrow(metadataAssemblySubTemp)){
    tempFasta <- readDNAStringSet(metadataAssemblySubTemp$NewblerFnaPath[i], format = "fasta")
    tempNames <- names(tempFasta)
    tempNamesTrunc <- sub(" .*", "", tempNames)
    names(tempFasta) <- tempNamesTrunc
    setkey(blastnNew, LibraryName)
    key(blastnNew)
    blastnNewSub <- blastnNew[.(metadataAssemblySubTemp$LibraryName[i])]
    blastnNewSub$newContigName <- paste(blastnNewSub$LibraryName, "_", blastnNewSub$qseqid, sep = "")
    tempFastaSub <- tempFasta[which(names(tempFasta) %in% blastnNewSub$qseqid)]
    names(tempFastaSub) <- blastnNewSub$newContigName
    writeXStringSet(tempFastaSub,
                    file = paste(pathFastq, "/", metadataAssemblySubTemp$LibraryName[i], 
                                 "_mitoHitsContigs.fasta", sep = ""),
                    append = FALSE,
                    format = "fasta")

    }

rm(tempFasta, tempFastaSub, tempNames, tempNamesTrunc)

# Add the name and path of the fasta files of contigs that were mitochondrial hits to the metadata table:
for(k in 1:nrow(metadataAssembly)){
    metadataAssembly$mitoContigsFasta <- paste(metadataAssembly$LibraryName, "_mitoHitsContigs.fasta", sep = "")
    metadataAssembly$mitoContigsFastaPath <- paste(pathFastq, metadataAssembly$mitoContigsFasta, sep = "")
}
```


Gzip the mito contigs fasta:
```{r}
prefix <- "GZipAfterMitoBlast"
node <- "24"
for(i in 1:nrow(metadataAssembly)){
    cmd <- with(metadataAssembly, 
            paste(" gzip ", paste(metadataAssembly$mitoContigsFastaPath, sep = ""),
                  sep = ""))
}

suffix <- ".sub" 
MakeQsubs(cmd, prefix, suffix, node)
```

* Done
Clean-up step: Remove the output files while keeping the qsub and bash file:
```{r}
system("/opt/gridengine/bin/linux-x64/qstat") # Remove qsub temp when qstat returns nothing.
RemoveQsubTempFiles(sharedPathAn, prefix)
```

Gene prediction software available on the biocluster:
glimmerHMM: $ ls -l /opt/bio/GlimmerHMM/...
genemark-es: $ /opt/bio/genemark-es/...
snap: $ /opt/bio/snap/...
geneid: $ /opt/bio/geneid/...

FungalITSextractor: $ /opt/bio/FungalITSextractor/...

Running Augustus:
```{r}
pathAugustus <- "/home/CFIA-ACIA/girouxeml/prog/augustus-3.2.3/bin/augustus"

prefix <- "Augustus"
dir.create(paste(sharedPathAn, prefix, sep = ""), showWarnings=TRUE, recursive=FALSE)
pathAugustusOutput <- paste(sharedPathAn, prefix, "/", sep = "")

i <- 1
for(i in 1:nrow(metadataAssembly)){
    cmd <- with(metadataAssembly, 
                paste("augustus --species=botrytis_cinerea --genemodel=complete ",
                      "--outfile=", paste(pathAugustusOutput,
                                          metadataAssembly$LibraryName,
                                          "_augustus_Botrytis_test1_completeGenesOnly.gff", sep = ""),
                      " ", metadataAssembly$NewblerFnaPath,
                      sep = ""))
}
                  

suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix, suffix)
```
* Done
Clean-up step: Remove the output files while keeping the qsub and bash file:
```{r}
system("/opt/gridengine/bin/linux-x64/qstat") # Remove qsub temp when qstat returns nothing.
RemoveQsubTempFiles(sharedPathAn, prefix)
```

* Done
Add the names of the Augustus gff files to the metadata table:
```{r}
for(k in 1:nrow(metadataAssembly)){
    metadataAssembly$Augustus1gff <- paste(metadataAssembly$LibraryName, "_augustus_Botrytis_test1_completeGenesOnly.gff", sep = "")
}

# Note, I made individual directories (manually at the end of the script for easier dir selection 
# for blast2go) and moved the gff files into them:
for(j in 1:length(metadataAssembly$LibraryName)){
  dir.create(paste(pathAugustusOutput, metadataAssembly$LibraryName[j], sep = ""),
             showWarnings = TRUE, recursive = FALSE)
}

for(j in 1:length(metadataAssembly$LibraryName)){
    cmd <- paste("mv ", paste(pathAugustusOutput, metadataAssembly$Augustus1gff, sep = ""),
                 " ", paste(pathAugustusOutput, metadataAssembly$LibraryName, "/", sep = ""),
                 sep = "")
}
system(cmd)

for(k in 1:nrow(metadataAssembly)){
    metadataAssembly$Augustus1gffPath <- paste(pathAugustusOutput,
                                               metadataAssembly$LibraryName, "/", 
                                               metadataAssembly$Augustus1gff, sep = "")
}
```

* Done
Retrieve the predicted protein sequences from the Augustus gff files for each genome:
```{r}
prefix <- "AugustusQsubAAcds"
i <- 1
for(i in 1:nrow(metadataAssembly)){
    # cmd <- with(metadataAssembly[2:7,],
    cmd <- with(metadataAssembly, 
                paste("getAnnoFasta.pl --protein=on --codingseq=on ", 
                      metadataAssembly$Augustus1gffPath, sep = ""))
}
suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix, suffix)
```

* Done
Clean-up step: Remove the output files while keeping the qsub and bash file:
```{r}
system("/opt/gridengine/bin/linux-x64/qstat") # Remove qsub temp when qstat returns nothing.
RemoveQsubTempFiles(sharedPathAn, prefix)
```
* Done
Add the names of the Augustus .aa files to the metadata table:
```{r}
# Add the suffix .fa to the Augustus1aa files and path (some downstream programs will not recognise the .aa suffix)
oldnames <- list.files(path = paste(sharedPathAn, "Augustus/", sep = ""), pattern = ".*_aa$", 
                       recursive = FALSE, full.names = TRUE)
file.rename(oldnames, paste0(oldnames, ".fa", sep = ""))

for(k in 1:nrow(metadataAssembly)){
    metadataAssembly$Augustus1aa <- paste(metadataAssembly$LibraryName, "_augustus_Botrytis_test1_completeGenesOnly_aa.fa", sep = "")
}


for(j in 1:length(metadataAssembly$LibraryName)){
    cmd <- paste("mv ", paste(pathAugustusOutput, metadataAssembly$Augustus1aa, sep = ""),
                 " ", paste(pathAugustusOutput, metadataAssembly$LibraryName, "/", sep = ""),
                 sep = "")
}
system(cmd)

for(k in 1:nrow(metadataAssembly)){
    metadataAssembly$Augustus1aaPath <- paste(pathAugustusOutput,
                                               metadataAssembly$LibraryName, "/", 
                                               metadataAssembly$Augustus1aa, sep = "")
}
```

* Done
Getting the ITS with the fungalITSextractor script:
First need the fasta file, not fastq:
```{r}
prefix <- "fastq2fasta_finalProcessedFastq"                

i <- 1

for(i in 1:nrow(metadataAssembly)){
   cmd <- with(metadataAssembly,
               paste(" seqtk fq2fa ", metadataAssembly$finalProcessedPath, " > ",
                     paste(pathFastq, metadataAssembly$LibraryName, ".3processed.fasta", sep = ""),
                     sep = ""))
}


suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix, suffix)
```

* Done
Clean-up step: Remove the output files while keeping the qsub and bash file:
```{r}
system("/opt/gridengine/bin/linux-x64/qstat") # Remove qsub temp when qstat returns nothing.
RemoveQsubTempFiles(sharedPathAn, prefix)
```

** Done
2nd: Use fasta in ITSx perl script (remake of FungalITSextractor.pl):
** I put inthe processed fastq files, instead of the newbler assemblies - perhaps it should have 
been the assemblies...
```{r}
#fungalITSpath <- "/opt/bio/FungalITSextractor/FungalITSextractor.pl"
prefix <- "fungalITSxtractorQsub_Lari_only"

i <- 1
for(i in 1:nrow(metadataAssembly)){
    cmd <- with(metadataAssembly,
                paste(" perl ", itsxPath, " ",
                      " -i ", metadataAssembly$finalProcessedPath,
                      " -t F ",               # F here is to specify fungal
                      " --save_regions all ", # This says I want all outputs, not just ITS 1 and 2
                      " -o ", paste(pathFastq, "ITSx_", metadataAssembly$LibraryName, sep = ""),
                      " --table T ",          # This is because I want a tble (True)
                      " --cpu 12 ",            # To run this in parallel
                      sep = ""))
}
cmd[3]
#suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix, suffix)
suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd[3], prefix, suffix) # to run Lhya only - since it zombied
```

* Not Done
Clean-up step: Remove the output files while keeping the qsub and bash file:
```{r}
system("/opt/gridengine/bin/linux-x64/qstat") # Remove qsub temp when qstat returns nothing.
RemoveQsubTempFiles(sharedPathAn, prefix)
```

* Done
Gzip the fasta reads that were INPUT to the ITSextractor 
```{r}
prefix <- "fungalITSx_gzipFastaQsubs"
cmd <- with(metadataAssembly, paste("gzip ", metadataAssembly$finalProcessedPath, sep = ""))

suffix <- ".sub"  
MakeQsubs(cmd, prefix, suffix)
```

* Not done yet
Running the GeneMark-ES annotation tool with the "fungi" option.
Doesn't require a training set.
```{r}
# pathGeneMarkES <- "/opt/bio/genemark-es/"
# Change above path to local install - still require perl dependencies setup.
```


*** Interproscan requires glibc > 2.14, but we have v 2.12 on the system.
Updating it or changing it is hell, and strongly advised against.
So the next chunk can't run successfully. 
we will need to run this on a standalone, or find a solution.

* Not done yet - running interproscan
Running it on the assembly, not the processed fastq.
There is a problem with the output directory - it`s not going to what I specified, instead it`s
putting the output in qsub directory in the temp folder, with the biocluster qsub name as prefix.
```{r}
interproPath <- "/home/CFIA-ACIA/girouxeml/prog/my_interproscan/interproscan-5.24-63.0/interproscan.sh"

prefix <- "interProScanQsubTestNoGene3d_all_outputs"
interproAppsNoGene3d <- "CDD-3.14,Coils-2.2.1,Hamap-201701.18,MobiDBLite-1.0,PANTHER-11.1,Pfam-31.0,PIRSF-3.02,PRINTS-42.0,ProDom-2006.1,ProSitePatterns-20.132,ProSiteProfiles-20.132,SMART-7.1,SUPERFAMILY-1.75,TIGRFAM-15.0"


i <- 1
node <- "24"
for(i in 1:nrow(metadataAssembly)){
    cmd <- with(metadataAssembly,
                paste(interproPath, " ",
                      " -i ", metadataAssembly$Augustus1aaPath,
                      " -appl ", interproAppsNoGene3d, 
                      " --cpu 24 ",
                      sep = ""))
}
cmd[3]
suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix, suffix, node)
```

# Create a directory for interpro outputs:
```{r}
interProSOutpath <- paste(sharedPathAn, prefix, "/", sep = "")

dir.create(paste(interProSOutpath, "/", 
                 paste(metadataAssembly$SppAbbr, "_interproscan_results_xml/", sep = ""),
                 sep = ""), 
           showWarnings = TRUE, 
           recursive    = FALSE)

for(k in 1:nrow(metadataAssembly)){
    metadataAssembly$InterPSoutDirPath <- paste(interProSOutpath,
                                                metadataAssembly$SppAbbr, "_interproscan_results_xml/",
                                                sep = "")
}
# Move the interproscan results to the new directories
for(j in 1:length(metadataAssembly$LibraryName)){
    cmd <- paste("mv ", paste(interProSOutpath, metadataAssembly$LibraryName, "_*", sep = ""), " ", metadataAssembly$InterPSoutDirPath, sep = "")
}

system(cmd)
```

Write the metadata table:
```{r}
library(data.table)
df <- apply(metadata,2,as.character)
write.table(df, 
            file = file.path(sharedPathAn, "Lachnellula_genomes_MetadataFirst.csv"), 
            sep = ",",
            #append = FALSE, 
            row.names = TRUE,
            col.names = NA,
            quote = FALSE)

df2 <- apply(metadataAssembly,2,as.character)
write.table(df2, 
            file = file.path(sharedPathAn, "Lachnellula_genomes_MetadataAssembly.csv"), 
            sep = ",",
            #append = FALSE, 
            row.names = TRUE,
            col.names = NA,
            quote = FALSE)

```


<!-- Run blast for blast2go -->
<!-- Set the Blast options and output format: -->
<!-- ```{r} -->
<!-- pathBlastp    <- "/opt/bio/ncbi-blast+/bin/blastp" -->
<!-- pathBlastDbNr <- "/isilon/biodiversity/reference/ncbi/blastdb/reference/nr/nr" -->

<!-- outFmt <- "5" -->
<!-- eval <- "1e-6" -->
<!-- numAligns <- "20" -->
<!-- maxHsps <- "20" -->
<!-- node <- "24" -->
<!-- ``` -->

<!-- Generate the bash scripts that will perform blasts of the query against each of the query databases made. -->
<!-- ```{r} -->
<!-- prefix <- "Aa_Blastp" -->
<!-- i <- 1 -->
<!-- for(i in 1:nrow(metadataAssembly)){ -->
<!--     cmd <- with(metadataAssembly, -->
<!--                 paste(pathBlastp, -->
<!--                       " -db ", pathBlastDbNr, -->
<!--                       " -query ", metadataAssembly$Augustus1aaPath, -->
<!--                       " -outfmt '", outFmt, -->
<!--                       " ' -out ", paste(sharedPathAn, prefix, "/", metadataAssembly$Augustus1aa, ".blastp.xml", sep = ""), -->
<!--                       #" -num_threads ", node, -->
<!--                       " -evalue ", eval, -->
<!--                       " -show_gis ", -->
<!--                       " -num_alignments ", numAligns, -->
<!--                       sep = "")) -->
<!-- } -->
<!-- cmd[1] -->
<!-- suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix, suffix, node) -->
<!-- ``` -->

<!-- Clean-up step: Remove the output files while keeping the qsub and bash file: -->
<!-- ```{r} -->
<!-- system("/opt/gridengine/bin/linux-x64/qstat") # Remove qsub temp when qstat returns nothing. -->
<!-- system("/opt/gridengine/bin/linux-x64/qhost")  -->
<!-- RemoveQsubTempFiles(sharedPathAn, prefix) -->
<!-- ``` -->

<!-- To run IGV on the biocluster, with gui, on linux computers, or computers with PuTTy + Xming: -->
<!-- $ java -Xmx1500m -jar /opt/bio/IGVTools/igvtools.jar gui -->
<!-- See: -->
<!-- https://software.broadinstitute.org/software/igv/igvtools_commandline -->

<!-- See about aligning reads for the ITS regions, trying Bioconductor package "DECIPHER" -->
<!-- ```{r} -->
<!-- library(Biostrings) -->
<!-- # For package DECIPHER, need to go to the command line in R in terminal and do: -->
<!-- # > source("https://bioconductor.org/biocLite.R") -->
<!-- # > biocLite("DECIPHER") -->
<!-- library(DECIPHER) -->
<!-- ``` -->


Split fasta to get a smaller set to blast:
Based on:
awk 'BEGIN {n_seq=0;} /^>/ {if(n_seq%1000==0){file=sprintf("myseq%d.fa",n_seq);} print >> file; n_seq++; next;} { print >> file; }' < sequences.fa
```{r}
newDir <- paste(paste(sharedPathAn, "Augustus/", metadataAssembly$LibraryName, sep = ""))
for(i in 1:length(newDir)){dir.create(newDir[i], showWarnings = TRUE, recursive = FALSE)}

for(i in 1:nrow(metadataAssembly)){
    cmd <- with(metadataAssembly, 
                #cat(paste(
                paste(
                paste(" awk 'BEGIN {n_seq=0;} /^>/ {if(n_seq%1000==0){file=sprintf(\"", sep = ""),
                paste(sharedPathAn,"Augustus/",metadataAssembly$LibraryName,"/", sep = ""),
                paste(metadataAssembly$LibraryName, "_%d.aa.fa\"", ",n_seq);} print >> file; ", sep = ""),
                paste(" n_seq++; next;} { print >> file; }' < ", sep = ""),
                paste(metadataAssembly$Augustus1aaPath, sep = ""),
                sep = ""))
}

# Enter these manually on command line, otherwise the backslash escape shows "\".
# Paths have been modified, so run the loop above again, and update the output below.
cat(cmd[1])
# awk 'BEGIN {n_seq=0;} /^>/ {if(n_seq%1000==0){file=sprintf("/home/CFIA-ACIA/girouxeml/PIRL_working_directory/Lachnellula_species_GenomeAn_IonTorrent_2017/Augustus/Lari_IonT_2017_1/Lari_IonT_2017_1_%d.aa.fa",n_seq);} print >> file;  n_seq++; next;} { print >> file; }' < /home/CFIA-ACIA/girouxeml/PIRL_working_directory/Lachnellula_species_GenomeAn_IonTorrent_2017/Augustus/Lari_IonT_2017_1_augustus_Botrytis_test1_completeGenesOnly_aa.fa

cat(cmd[2])
#awk 'BEGIN {n_seq=0;} /^>/ {if(n_seq%1000==0){file=sprintf("/home/CFIA-ACIA/girouxeml/PIRL_working_directory/Lachnellula_species_GenomeAn_IonTorrent_2017/Augustus/Lcer_IonT_2017_1/Lcer_IonT_2017_1_%d.aa.fa",n_seq);} print >> file;  n_seq++; next;} { print >> file; }' < /home/CFIA-ACIA/girouxeml/PIRL_working_directory/Lachnellula_species_GenomeAn_IonTorrent_2017/Augustus/Lcer_IonT_2017_1_augustus_Botrytis_test1_completeGenesOnly_aa.fa

cat(cmd[3])
#awk 'BEGIN {n_seq=0;} /^>/ {if(n_seq%1000==0){file=sprintf("/home/CFIA-ACIA/girouxeml/PIRL_working_directory/Lachnellula_species_GenomeAn_IonTorrent_2017/Augustus/Lhya_IonT_2017_1/Lhya_IonT_2017_1_%d.aa.fa",n_seq);} print >> file;  n_seq++; next;} { print >> file; }' < /home/CFIA-ACIA/girouxeml/PIRL_working_directory/Lachnellula_species_GenomeAn_IonTorrent_2017/Augustus/Lhya_IonT_2017_1_augustus_Botrytis_test1_completeGenesOnly_aa.fa

cat(cmd[4])
#awk 'BEGIN {n_seq=0;} /^>/ {if(n_seq%1000==0){file=sprintf("/home/CFIA-ACIA/girouxeml/PIRL_working_directory/Lachnellula_species_GenomeAn_IonTorrent_2017/Augustus/Locc_IonT_2017_1/Locc_IonT_2017_1_%d.aa.fa",n_seq);} print >> file;  n_seq++; next;} { print >> file; }' < /home/CFIA-ACIA/girouxeml/PIRL_working_directory/Lachnellula_species_GenomeAn_IonTorrent_2017/Augustus/Locc_IonT_2017_1_augustus_Botrytis_test1_completeGenesOnly_aa.fa

cat(cmd[5])
#awk 'BEGIN {n_seq=0;} /^>/ {if(n_seq%1000==0){file=sprintf("/home/CFIA-ACIA/girouxeml/PIRL_working_directory/Lachnellula_species_GenomeAn_IonTorrent_2017/Augustus/Lsub_IonT_2017_1/Lsub_IonT_2017_1_%d.aa.fa",n_seq);} print >> file;  n_seq++; next;} { print >> file; }' < /home/CFIA-ACIA/girouxeml/PIRL_working_directory/Lachnellula_species_GenomeAn_IonTorrent_2017/Augustus/Lsub_IonT_2017_1_augustus_Botrytis_test1_completeGenesOnly_aa.fa

cat(cmd[6])
#awk 'BEGIN {n_seq=0;} /^>/ {if(n_seq%1000==0){file=sprintf("/home/CFIA-ACIA/girouxeml/PIRL_working_directory/Lachnellula_species_GenomeAn_IonTorrent_2017/Augustus/Lsue_IonT_2017_1/Lsue_IonT_2017_1_%d.aa.fa",n_seq);} print >> file;  n_seq++; next;} { print >> file; }' < /home/CFIA-ACIA/girouxeml/PIRL_working_directory/Lachnellula_species_GenomeAn_IonTorrent_2017/Augustus/Lsue_IonT_2017_1_augustus_Botrytis_test1_completeGenesOnly_aa.fa

cat(cmd[7])
#awk 'BEGIN {n_seq=0;} /^>/ {if(n_seq%1000==0){file=sprintf("/home/CFIA-ACIA/girouxeml/PIRL_working_directory/Lachnellula_species_GenomeAn_IonTorrent_2017/Augustus/Lawi_IonT_Debbie_1/Lawi_IonT_Debbie_1_%d.aa.fa",n_seq);} print >> file;  n_seq++; next;} { print >> file; }' < /home/CFIA-ACIA/girouxeml/PIRL_working_directory/Lachnellula_species_GenomeAn_IonTorrent_2017/Augustus/Lawi_IonT_Debbie_1_augustus_Botrytis_test1_completeGenesOnly_aa.fa
```

Perform a blast on the split fasta files.
```{r}

prefix <- "Aa_Blastp_splitFastas3"

aaForBlastFiles <- list.files(path = paste(sharedPathAn, "Augustus/", metadataAssembly$LibraryName, "/", sep = ""), 
                              pattern = "*\\.aa\\.fa$", recursive = FALSE, full.names = TRUE)

node <- 11
i <- 1
for(i in 1:length(aaForBlastFiles)){
    cmd <- paste(pathBlastp,
                 " -db ", pathBlastDbNr,
                 " -query ", aaForBlastFiles,
                 " -outfmt '", outFmt,
                 " ' -out ", paste(aaForBlastFiles, ".blastp.xml", sep = ""),
                 " -num_threads ", node,
                 " -evalue ", eval,
                 " -show_gis ",
                 " -num_alignments ", numAligns,
                 #" -max_hsps_per_subject ", maxHsps,
                 sep = "")
}
cmd[1]

suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix, suffix, node)
```

To see which .xml files have had something written to them (shows that there is progress in the 
blast search), cd to the Augustus directory, and in the terminal command line type:
$ find . -type f -name "*.xml" -size +1c -exec ls -sh {} \;
. means for the childs of the current directorie
-type f means files
-name "*.xml" is to search for filenames with the .xml suffix
-size +1c means to search for files with greater than 1, c = bytes
-exec ls -sh {} \; means to use the option -exec to execute another command, in this case to list these
directories with their sizes.

See:
https://superuser.com/questions/204564/how-can-i-find-files-that-are-bigger-smaller-than-x-bytes

Retrieval of CAZy families of Lachnellula amino acids fasta with dbCAN:

Paths specific to dbCAN pipeline with hmmer3 dependencies: 
Note: hmmer3 is already on the biocluster dbCAN downloads were placed in our References directory
```{r}
dbCANpath   <- "/home/CFIA-ACIA/girouxeml/PIRL_working_directory/References/CAZyTools/dbCAN-fam-HMMs.txt"
hmmPress    <- "/opt/bio/hmmer3/bin/hmmpress"
hmmScanPath <- "/opt/bio/hmmer3/bin/hmmscan"
hmmParser   <- "/home/CFIA-ACIA/girouxeml/PIRL_working_directory/References/CAZyTools/hmmscan-parser.sh"
```

Setting things up for dbCAN:
```{r}
cmd <- paste(hmmPress, " ", dbCANpath, sep = "")
system(cmd)
```

Create a directory in the output directory for each reference species Run hmmscan for each reference species
```{r}
prefix <- "A_dbCAN_all_refs"
node <- 1

for(j in 1:length(metadataAssembly$ScientificName)){
  dir.create(paste(sharedPathAn, metadataAssembly$ScientificName[j], sep = ""),
             showWarnings = TRUE, recursive = FALSE)
}

cmd <- with(metadataAssembly,
            paste(hmmScanPath,
                  " --domtblout ", paste(sharedPathAn, ScientificName, "/", ScientificName, ".CAZy.out.dm", sep = ""),
                  #" ", dbCANpath, " ", paste(projRefPath, ProteinsFasta, sep = ""),
                  " ", dbCANpath, " ", Augustus1aaPath,
                  " > ", paste(sharedPathAn, ScientificName, "/", ScientificName, ".out", sep = ""),
                  sep = ""))

suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix, suffix, node)
```
To remove the output files after you are done:
```{r}
system("/opt/gridengine/bin/linux-x64/qstat") # Remove qsub temp when qstat returns nothing.
RemoveQsubTempFiles(sharedPathAn, prefix)
```

Add the name of the output tables from dbCAN to the metadata table:
```{r}
metadataAssembly$domtblout <- paste(metadataAssembly$ScientificName, ".CAZy.out.dm", sep = "")
metadataAssembly$domtbloutPath <- paste(sharedPathAn, metadataAssembly$ScientificName, "/", metadataAssembly$domtblout, sep = "")
metadataAssembly$dbHmmScanOut <- paste(metadataAssembly$ScientificName, ".out", sep = "")
metadataAssembly$dbScanOutPath <- paste(sharedPathAn, metadataAssembly$ScientificName, "/", metadataAssembly$dbHmmScanOut, sep = "")
```

####################################################################################################
Below is the script I used for extracting CAZy for the Pythium RNA-Seq project
####################################################################################################

See how many CAZy were pulled out for Pyuu: look for this in the .CAZy.out.dm file
```{r}
library(reshape2)
library(data.table)
# test[[i]] <- fread(dbCANList[i], sep = "auto", header = FALSE)

metadataAssembly$domtbloutPath[7] # This is for Lawi
cazyLawiAll <- fread(metadataAssembly$domtbloutPath[7], sep = "auto", header = TRUE, fill=TRUE)
cazyLawiAll <- cazyLawiAll[-c(1, 2), ]
# rename some columns:
colnames(cazyLawiAll)[1] <- "cazyFam"
# get the unique cazy families:
cazyFams <- unique(cazyLawiAll$cazyFam)
# get the unique genes
lawiCazyGenes <- unique(cazyLawiAll$sequence)
length(lawiCazyGenes)
# Now make a new table that has only the cazyFam and sequence columns
cazyFamGene <- subset(cazyLawiAll, select=c("cazyFam", "sequence"))
cazyFamGene$cazyFam <- sub(".hmm", "", cazyFamGene$cazyFam)
# Now collapse rows that have duplicates to one row
library("dplyr")
cazyFamGene <- distinct(cazyFamGene)
length(cazyFams)
# Sort by CAZy family
sort1 <- with(cazyFamGene, cazyFamGene[order(-cazyFam, sequence)  , ])
sort2 <- with(cazyFamGene, cazyFamGene[order(sequence, cazyFam)  , ])
cazyFamGene <- sort1
```
Run the hmmscan parser on the hmmscan output for each reference species:
```{r}
prefix <- "B_dbCAN_hmmscanParser"

cmd <- with(metadataAssembly,
            paste(" sh " , hmmParser,
                  " ", domtbloutPath,
                  " > ", paste(sharedPathAn, ScientificName, "/", ScientificName, ".out.dm.ps", sep = ""),
                  sep = ""))

suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix, suffix, node)
```
To remove the output files after you are done:
```{r}
system("/opt/gridengine/bin/linux-x64/qstat") # Remove qsub temp when qstat returns nothing.
RemoveQsubTempFiles(sharedPathAn, prefix)
```

Add the name of the output hmm tables from dbCAN to the metadata table:
```{r}
metadataAssembly$Parseddmtbl <- paste(metadataAssembly$ScientificName, ".out.dm.ps", sep = "")
metadataAssembly$ParsedmtblPath <- paste(sharedPathAn, metadataAssembly$ScientificName, "/", metadataAssembly$Parseddmtbl, sep = "")
fwrite(metadataAssembly, 
            file = file.path(paste(sharedPathAn, "referencesMetadataFinal.csv", sep = "")),
            append    = FALSE, 
            sep       = ",",
            quote     = FALSE,
            row.names = TRUE,
            col.names = TRUE)
```

*** Over here!!!
Would like to generate a table with the captured CAZy proteins, for specific CAZy families:
```{r}
library(reshape2)
library(data.table)

dbCANList <- metadataAssembly$ParsedmtblPath
i <- 1
test <- lapply(dbCANList, fread, sep = "auto", header = FALSE)
namesCols <- c("family.hmm", "hmm.length", "query.id", "query.length", "e.val",
               "hmm.start", "hmm.end", "query.start", "query.end", "coverage")
for(i in 1:length(test)){
  setnames(test[[i]], 1:10, namesCols)
}

for(i in 1:length(test)){
	test[[i]]$ScientificName <- basename(dbCANList[i])
	test[[i]]$ScientificName <- sub(".out.dm.ps", "", test[[i]]$ScientificName)
	print(nrow(test[[i]]))
	}

summary(test)

View(test[[1]])

lapply(test, function(i) setkey(i))
testAll <- Reduce(function(...) merge(..., all = T), test)
testAll$family.hmm <- sub(".hmm", "", testAll$family.hmm)

write.table(testAll,
            file = file.path(paste(sharedPathAn, "dbCAN_CAZySubset_AllRefs.csv", sep = "")),
            append    = FALSE, 
            sep       = ",",
            quote     = FALSE,
            row.names = TRUE,
            col.names = NA)
```

A function to generate tables. This is good to keep as an example of how you can generate this programmatically.
```{r}
library(knitr)
rmarkdownTable <- function(df){
  cat(paste(names(df), collapse = "|"))
  cat("\n")
  cat(paste(rep("-", ncol(df)), collapse = "|"))
  cat("\n")
  
  for(i in 1:nrow(df)){
    cat(paste(df[i,], collapse = "|"))
    cat("\n")
    }
invisible(NULL)
}
rmarkdownTable(head(countCAZyFam))
```

Need to add a column to the dbCAN data table with the names I want in the phylogeny trees for each species.
```{r}
library(data.table)
library("dplyr")
# Going to start with the big table, and then pull out rows by CAZy family for the ones I need

dbCAN_tempFile <- fread(paste(sharedPathAn, "dbCAN_CAZySubset_AllRefs.csv", sep = ""),
                        sep="auto", header = TRUE)

# Need to add a column for species abbreviations:
dbCAN_tempFile$SppAbbr <- dbCAN_tempFile$ScientificName

sppAbbr <- c("Lari", "Lcer", "Lhya", "Locc", "Lsub", "Lsue", "Lawi")
sppAbbrRef <- c("Lachnellula_arida"="Lari", "Lachnellula_cervina"="Lcer", "Lachnellula_hyalina"="Lhya",
                "Lachnellula_occidentalis"="Locc", "Lachnellula_subtilissima"="Lsub", "Lachnellula_suecica"="Lsue",
                "Lachnellula_willkommii"="Lawi")

dtAbbr <- as.data.table(sppAbbrRef)
dtAbbr$ScientificName <- unique(dbCAN_tempFile$ScientificName)

names(dtAbbr)[1] <- "newValue"
names(dtAbbr)[2] <- "SppAbbr" 


# Add species abbreviations to a new column, using the species name to insert the abbreviation:
setkey(dbCAN_tempFile, SppAbbr)
setkey(dtAbbr, SppAbbr)
dbCAN_tempFile[dtAbbr, SppAbbr := newValue] # Finally this works!!!
newNamesdt <- subset(dbCAN_tempFile, select=c("family.hmm", "query.id", "SppAbbr"))
dbCAN_tempFile$Name2 <- dbCAN_tempFile$query.id
dbCAN_tempFile$Name2 <- paste(dbCAN_tempFile$SppAbbr, dbCAN_tempFile$Name2, sep = "_")

View(dbCAN_tempFile)
dbCAN_tempFile[, c("V1"):=NULL]

write.table(dbCAN_tempFile, 
           file = file.path(paste(sharedPathAn, "dbCAN_CAZySubset_AllRefs_finalNames.csv", sep = "")),
           append    = FALSE, 
           sep       = ",",
           quote     = FALSE,
           row.names = TRUE,
           col.names = NA)
```

Need to edit the gff3 output from Augustus:
Consider the packages:
http://bioconductor.org/packages/rtracklayer/
git clone https://git.bioconductor.org/packages/rtracklayer
```{r}
# read.delim("/home/CFIA-ACIA/girouxeml/PIRL_working_directory/Lachnellula_species_GenomeAn_IonTorrent_2017/Augustus/Lari_IonT_2017_1_augustus_Botrytis_test1_completeGenesOnly.gff", header = F, comment.char = "#") -> gff3

# Andre just did the folllowing:
gff_file <- read.delim(metadataAssembly$Augustus1gffPath[1], header = FALSE, comment.char = "#", stringsAsFactors = FALSE)

b2gAnnotPath <- paste(sharedPathAn, "Lachnellula_arida/", sep = "")


# Better:
#gff <- gffRead("/home/CFIA-ACIA/girouxeml/PIRL_working_directory/Lachnellula_species_GenomeAn_IonTorrent_2017/Augustus/Lari_IonT_2017_1_augustus_Botrytis_test1_completeGenesOnly.gff")

library(BiocInstaller)
biocLite("rtracklayer")
library(rtracklayer)
# Don't update source packages

#gff <- import.gff("/home/CFIA-ACIA/girouxeml/PIRL_working_directory/Lachnellula_species_GenomeAn_IonTorrent_2017/Augustus/Lari_IonT_2017_1_augustus_Botrytis_test1_completeGenesOnly.gff")

#gff3 <- import.gff3("/home/CFIA-ACIA/girouxeml/PIRL_working_directory/Lachnellula_species_GenomeAn_IonTorrent_2017/interProScanQsubTestNoGene3d_all_outputs/Lari_IonT_2017_1_augustus_Botrytis_test1_completeGenesOnly.aa.gff3")

```

Trying a perl script that merges annotations with gff:
```{r}
mergeB2GannotGFF <- "/home/CFIA-ACIA/girouxeml/prog/scripts_pl/merge_blast2goannot_gff.pl"


b2gAnnotFiles <- list.files(path = paste(sharedPathAn, metadataAssembly$ScientificName, "/", sep = ""),
                            pattern = ".*.annot$", recursive = FALSE, full.names = TRUE)

file.rename(b2gAnnotFiles, paste0(gsub(pattern = "_annot_[0-9]+_[0-9]+", replacement = "_b2g_annot", b2gAnnotFiles)))

metadataAssembly$b2gAnnotFile <- paste(metadataAssembly$SppAbbr, "_b2g_annot.annot", sep = "")
metadataAssembly$b2gAnnotPath <- paste(sharedPathAn, metadataAssembly$ScientificName, "/", metadataAssembly$b2gAnnotFile, sep = "")

# Doesn't work - annotations are not merged.
cmd <- paste("perl ", mergeB2GannotGFF,
             " -b ", metadataAssembly$b2gAnnotPath[1],
             " -g ", metadataAssembly$Augustus1gffPath[1],
             " > ", paste(sharedPathAn, metadataAssembly$ScientificName[1], "/", metadataAssembly$SppAbbr[1], ".blast2go.gff", sep = ""),
             sep = "")
system(cmd)
```

Using Blast2GO to create NCBI genome submission files. This requires the Pro version, so I've been
using the trial. Key issue I had was that there were sequence descriptions after the sequence name
of each contig inthe assembly files from Newbler, and this was causing the tool to be unable to
create files from and process any of the sequences. If you want to remove the description and
if your headers are structured like that:
"> + id + space + description"

Once this part was removed, the tool worked.

i.e.,

>contig00001 1203988 12890445
agccctgcgatcgatcgggctagctagc

using sed:
$ sed -e 's/^\(>[^[:space:]]*\).*/\1/' Lari_assembly_EG2017.fna > Lari_assembly_EG2017_mod.fna

new format:
>contig00001
agccctgcgatcgatcgggctagctagc

Now it works.




